{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time we use 'TE_scores_MRI_serieel_nieuw.xlsx' and use only baseline and 12th month! This part is for data preparation, after we have saved diff_result.csv, we can skip this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "file_path = \"../../data/TE_scores_MRI_serieel_nieuw.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.drop(df.columns[0], axis=1)  # remove the first column\n",
    "\n",
    "# 移除 \"SCANdatum\" 和 \"Scoredatum\" 列\n",
    "columns_to_remove = ['SCANdatum']\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "df = df[(df['hoeveelste_MRI'] == 1) | (df['hoeveelste_MRI'] == 4)]  # select baseline and 12-month follow up scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_fpath = \"../../data/patient_id_with_category.csv\"  # read in category\n",
    "# 尝试使用不同的编码方式读取CSV文件\n",
    "try:\n",
    "    df_categoroy = pd.read_csv(category_fpath, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    df_categoroy = pd.read_csv(category_fpath, encoding='latin1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_categoroy, left_on='TENR', right_on='patient_id', how='outer')  # merge the two dataframes according to patient ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('scores_of_baseline_with_12month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('scores_of_baseline_with_12month.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个列表来存储满足条件的列\n",
    "for reader_id in ['1', '2']:\n",
    "    columns_to_sum = []\n",
    "    # 遍历DataFrame的列名\n",
    "    for column in merged_df.columns:\n",
    "        # 如果列名的最后一个字符是'1'，并且不包含'ERO'\n",
    "        if column.endswith(reader_id) and 'ERO' not in column:\n",
    "            columns_to_sum.append(column)\n",
    "    merged_df[f'tot_inflammation_{reader_id}'] = merged_df[columns_to_sum].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取Excel文件\n",
    "# file_path = '../TE_analysefile_for_Tahereh_zijde.xlsx'\n",
    "file_path = \"../../data/TE_scores_MRI_serieel_nieuw.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 移除 \"SCANdatum\" 和 \"Scoredatum\" 列\n",
    "columns_to_remove = ['SCANdatum']\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "remove_ls = [365, 387, 399, 458]  # these patients have no second scans\n",
    "\n",
    "# 根据条件将 DataFrame 拆分为两个\n",
    "condition = df['TENR'].isin(remove_ls)\n",
    "df_no_second_scan = df[condition]\n",
    "df = df[~condition]\n",
    "\n",
    "placebo_df = df[df['treatment'] == 0]\n",
    "df = df[df['treatment'] == 1]\n",
    "\n",
    "# 提取所有有baseline的患者\n",
    "baseline_df = df[df['VISNUMMER'] == 1]\n",
    "\n",
    "# 提取所有有second的患者\n",
    "second_df = df[df['VISNUMMER'] != 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两个数据框，基于ID进行对齐\n",
    "merged_df = pd.merge(baseline_df, second_df, on='TENR', suffixes=('_baseline', '_12month'), how='inner').copy()\n",
    "\n",
    "# 计算second的临床数据减去baseline的临床数据\n",
    "result_df = merged_df.copy()\n",
    "clinical_columns = [i for i in df.columns if 'tot' in i.lower()]  \n",
    "clinical_columns_baseline = [i + '_baseline' for i in clinical_columns] #\n",
    "clinical_columns_12month = [i + '_12month' for i in clinical_columns] #\n",
    "\n",
    "# merged_df_clean = merged_df[clinical_columns_baseline + clinical_columns_12month]\n",
    "# merged_df_clean.dropna()\n",
    "\n",
    "for column in clinical_columns:\n",
    "    merged_df[column + '_diff'] = merged_df[column + '_12month'] - merged_df[column + '_baseline']\n",
    "\n",
    "# 选择需要保存的列\n",
    "result_columns = ['TENR'] + clinical_columns_baseline + clinical_columns_12month + [column + '_diff' for column in clinical_columns]\n",
    "\n",
    "# 保存结果为新的Excel文件\n",
    "result_df = merged_df[result_columns].copy()\n",
    "result_df.rename(columns={'TENR': 'ID'}, inplace=True)\n",
    "result_df.dropna(inplace=True)\n",
    "result_df.to_excel('../../data/diff_result_3.xlsx', index=False)\n",
    "result_df.to_csv('../../data/diff_result_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This part is for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('../../data/diff_result_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(category, threshold_baseline):\n",
    "    print(f\"start category: {category} with threshold of {threshold_baseline}\")\n",
    "    baseline_name = 'Tot_' + category + '_baseline'\n",
    "    diff_name = baseline_name.replace('baseline', 'diff')\n",
    "    diff_pred_name = diff_name + '_pred'\n",
    "    diff_bin_name = diff_name + '_bin'\n",
    "    diff_pred_fold_name = diff_pred_name + '_fold'  # the prediction in this fold\n",
    "    \n",
    "    \n",
    "    # 提取 x 和 y 列\n",
    "    x = filtered_df[baseline_name]\n",
    "    y = filtered_df[diff_name]\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y) # 计算线性回归\n",
    "    filtered_df[diff_pred_name] = slope * x + intercept  # 计算预测值\n",
    "    R = np.corrcoef(x, y)[0, 1]  # 计算皮尔逊相关系数\n",
    "    \n",
    "    # 创建 Tot_baseline_bin 列\n",
    "    filtered_df[diff_bin_name] = np.where(filtered_df[diff_name] < threshold_baseline, 0, 1)\n",
    "\n",
    "    # 新增一列用于存储预测值\n",
    "    filtered_df[diff_pred_fold_name] = np.nan\n",
    "\n",
    "    # 分成4折\n",
    "    folds = 3\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=711)\n",
    "\n",
    "    # 存储每折的结果\n",
    "    roc_auc_list = []\n",
    "    roc_auc_list_train = []\n",
    "    max_f1_values = []\n",
    "    max_f1_values_train = []\n",
    "    sensitivity_ls = []\n",
    "    precision_ls = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(filtered_df)):\n",
    "        print(f\"------fold {fold+1}----\")\n",
    "        train_data = filtered_df.iloc[train_index]\n",
    "        test_data = filtered_df.iloc[test_index]\n",
    "\n",
    "        # 训练模型（使用线性回归，你也可以替换为其他模型）\n",
    "        x_train = train_data[baseline_name]\n",
    "        y_train = train_data[diff_name]\n",
    "        # print(x_train.shape, y_train.shape)\n",
    "    \n",
    "        # 在训练集上进行预测\n",
    "        print('----start training ... ----')\n",
    "        \n",
    "        model = np.polyfit(x_train.squeeze(), y_train, 1)\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x_train, y_train) # 计算线性回归\n",
    "        slope2 = model[0]\n",
    "        intercept2 = model[1]\n",
    "        print(f'slope_train: {slope:.2f}, intercept_train: {intercept:.2f}, r_value_train: {r_value:.2f}')\n",
    "\n",
    "\n",
    "        print(x_train.shape, y_train.shape)\n",
    "\n",
    "        y_pred_train = np.polyval(model, x_train.squeeze())\n",
    "        # 保存预测值到 result_df 中\n",
    "        filtered_df.iloc[train_index, filtered_df.columns.get_loc(diff_pred_fold_name)] = y_pred_train\n",
    "\n",
    "        # 计算 ROC 曲线和 AUC 值\n",
    "        fpr, tpr, thresholds = roc_curve(train_data[diff_bin_name], y_pred_train)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc_list_train.append(roc_auc)\n",
    "\n",
    "\n",
    "        matrix = confusion_matrix(train_data[diff_bin_name], y_pred_train > threshold_baseline)\n",
    "        print('confusion_matrix', matrix)\n",
    "        # f1_train= f1_score(train_data[diff_bin_name], y_pred_train > threshold_baseline)\n",
    "        # max_f1_values_train.append(f1_train)\n",
    "\n",
    "        # 打印每折的结果\n",
    "        print(f\"ROC AUC 值：{roc_auc:.2f}\")\n",
    "        print('----end training ... ----')\n",
    "\n",
    "        \n",
    "        \n",
    "        # 在测试集上进行预测\n",
    "        print('----start testing ... ----')\n",
    "\n",
    "        x_test = test_data[[baseline_name]].squeeze()\n",
    "        y_test = test_data[diff_name]\n",
    "        \n",
    "        print(x_test.shape, y_test.shape)\n",
    "        # slope, intercept, r_value, p_value, std_err = linregress(x_test, y_test) # 计算线性回归\n",
    "        # print('slope_test, intercept_test, r_value_test', slope, intercept, r_value)\n",
    "\n",
    "\n",
    "        y_pred_test = np.polyval(model, x_test.squeeze())\n",
    "        # 保存预测值到 result_df 中\n",
    "        filtered_df.iloc[test_index, filtered_df.columns.get_loc(diff_pred_fold_name)] = y_pred_test\n",
    "\n",
    "        # 计算 ROC 曲线和 AUC 值\n",
    "        fpr, tpr, thresholds = roc_curve(test_data[diff_bin_name], y_pred_test)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_auc_list.append(roc_auc)\n",
    "\n",
    "        matrix = confusion_matrix(test_data[diff_bin_name], y_pred_test > threshold_baseline)\n",
    "        print('confusion_matrix', matrix)\n",
    "\n",
    "        # f1_test= f1_score(test_data[diff_bin_name], y_pred_test > threshold_baseline)\n",
    "        # max_f1_values.append(f1_test)\n",
    "\n",
    "        # 打印每折的结果\n",
    "        print(f\"Testing data set: ROC AUC 值：{roc_auc:.2f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "            # 绘制 预测散点图\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 3.6))\n",
    "        ax1.scatter(x_test, y_test, color='black', s=10)\n",
    "        # print(x_test.to_numpy())\n",
    "        # print('---')\n",
    "        # print(y_pred)\n",
    "        # break\n",
    "        min_idx = np.argmin(x_test.to_numpy())\n",
    "        max_idx = np.argmax(x_test.to_numpy())\n",
    "        ax1.set_xlabel('baseline')\n",
    "        ax1.set_ylabel('score diff label')\n",
    "        ax1.set_xlim(0, max(filtered_df[baseline_name]))\n",
    "        ax1.set_ylim(min(filtered_df[diff_name]), max(filtered_df[diff_name]))\n",
    "        ax1.axhline(y=threshold_baseline, color='grey', linestyle='--', label=f'y = {threshold_baseline}')\n",
    "        ax1.plot([x_test.to_numpy()[min_idx], x_test.to_numpy()[max_idx]], [y_pred_test[min_idx], y_pred_test[max_idx]], color='navy', lw=1, linestyle='--')\n",
    "        x_cross_value = (threshold_baseline - intercept)/slope\n",
    "        print(f\"x_cross_value = {x_cross_value}\")\n",
    "        ax1.axvline(x=x_cross_value, color='grey', linestyle='--', label=f'y = {x_cross_value}')\n",
    "        ax1.axvline(x=-threshold_baseline, color='grey', linestyle='--', label=f'y = {threshold_baseline}')\n",
    "\n",
    "\n",
    "        ax1.plot(x_test.to_numpy(), x_test.to_numpy() * slope + intercept, color='navy', lw=1, linestyle='--')\n",
    "\n",
    "        # scatter = ax2.scatter(y_pred, y_test, color='blue', s=10)\n",
    "        # 绘制横线y=-3.12\n",
    "        ax2.axhline(y=threshold_baseline, color='grey', linestyle='--', label=f'y = {threshold_baseline}')\n",
    "        # 绘制竖线x=-3.12\n",
    "        ax2.axvline(x=threshold_baseline, color='grey', linestyle='--', label=f'x = {threshold_baseline}')\n",
    "\n",
    "        # ax2.yaxis.set_label_position('right')\n",
    "        ax2.set_ylabel('score diff label')\n",
    "        ax2.set_xlabel('score diff pred')  \n",
    "        \n",
    "        # 获取x轴和y轴的最大最小值\n",
    "        xy_min, xy_max = min(filtered_df[diff_name]), max(filtered_df[diff_name])\n",
    "\n",
    "\n",
    "        # 设置x轴和y轴的最大最小值一致\n",
    "        ax2.set_xlim(xy_min, xy_max)\n",
    "        ax2.set_ylim(xy_min, xy_max)\n",
    "\n",
    "        # 划分四个区域的数据点\n",
    "        TN_data = (y_pred_test > threshold_baseline) & (y_test > threshold_baseline)\n",
    "        FP_data = (y_pred_test < threshold_baseline) & (y_test > threshold_baseline)\n",
    "        FN_data = (y_pred_test > threshold_baseline) & (y_test < threshold_baseline)\n",
    "        TP_data = (y_pred_test < threshold_baseline) & (y_test < threshold_baseline)\n",
    "\n",
    "        # 统计每个区域的数据点个数\n",
    "        TN = sum(TN_data)\n",
    "        FN = sum(FN_data)\n",
    "        FP = sum(FP_data)\n",
    "        TP = sum(TP_data)\n",
    "        \n",
    "        sensitivity = TP / (TP + FN)\n",
    "        precision = TP / (TP + FP)\n",
    "        sensitivity_ls.append(sensitivity)\n",
    "        precision_ls.append(precision)\n",
    "        f1 = 2 * TP / (2 * TP + FP + FN)\n",
    "        specificity = TN / (FP + TN)\n",
    "        # print('two f1: ', f1, f1_test)s\n",
    "        # 在图中标注每个区域的数据点个数\n",
    "        ax2.text(xy_max * 0.6, xy_max * 0.8, f'TN: {TN}', ha='center', va='center', fontsize=12, color='blue')\n",
    "        ax2.text(xy_min * 0.8, xy_max * 0.8, f'FP: {FP}', ha='center', va='center', fontsize=12, color='red')\n",
    "        ax2.text(xy_max * 0.6, xy_min * 0.9, f'FN: {FN}', ha='center', va='center', fontsize=12, color='darkorange')\n",
    "        ax2.text(xy_min * 0.8, xy_min * 0.9, f'TP: {TP}', ha='center', va='center', fontsize=12, color='green')\n",
    "\n",
    "        x_baseline_min = 0\n",
    "        x_baseline_max = max(x_test)\n",
    "        ax1.text(x_baseline_max * 0.9, xy_max * 0.8, f'FP: {FP}', ha='center', va='center', fontsize=12, color='red')\n",
    "        ax1.text(x_baseline_max * 0.2, xy_max * 0.8, f'TN: {TN}', ha='center', va='center', fontsize=12, color='blue')\n",
    "        ax1.text(x_baseline_max * 0.9, xy_min * 0.9, f'TP: {TP}', ha='center', va='center', fontsize=12, color='green')\n",
    "        ax1.text(x_baseline_max * 0.2, xy_min * 0.9, f'FN: {FN}', ha='center', va='center', fontsize=12, color='darkorange')\n",
    "\n",
    "        # ax2.text(xy_min * 0.6, xy_max * 0.6, f'F1={f1:.2f}', ha='center', va='center', fontsize=12, color='black')\n",
    "        # ax2.set_title)\n",
    "\n",
    "        # 在散点图中分别绘制四个区域的数据点，并使用不同颜色\n",
    "        ax2.scatter(y_pred_test[TN_data], y_test[TN_data], color='blue', s=10, label='Top Right')\n",
    "        ax2.scatter(y_pred_test[FN_data], y_test[FN_data], color='darkorange', s=10, label='Top Left')\n",
    "        ax2.scatter(y_pred_test[FP_data], y_test[FP_data], color='red', s=10, label='Bottom Right')\n",
    "        ax2.scatter(y_pred_test[TP_data], y_test[TP_data], color='green', s=10, label='Bottom Left')\n",
    "        ax2.set_title(f'F1={f1:.2f}, Sensitivity (recall, true positive rate)={sensitivity:.2f}, Precision={precision:.2f}, Specificity (true negative rate)={specificity:.2f}, AUC={roc_auc:.2f}', ha='center', fontsize=12)\n",
    "\n",
    "\n",
    "        # 绘制 ROC 曲线\n",
    "        # plt.figure(figsize=(2, 2))\n",
    "        ax3.plot(fpr, tpr, color='black', lw=2, label='(area = {:.2f})'.format(roc_auc))\n",
    "        # ax3.text(max(fpr) * 0.8, min(tpr) * 0.9, f'AUC={roc_auc:.2f}', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        ax3.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        ax3.set_xlabel('False Positive Rate')\n",
    "        # ax3.yaxis.set_label_position('right')\n",
    "        ax3.set_ylabel('True Positive Rate')\n",
    "        # ax3.set_title(f'ROC Curve (AUC={roc_auc:.2f})')\n",
    "        plt.subplots_adjust(right=1.2)\n",
    "\n",
    "        # plt.legend(loc='lower right')\n",
    "        plt.suptitle(f'{category}. Fold {fold+1} / {folds} (validation data).', fontsize=16, y=1.05)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # 绘制散点图和回归线\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(filtered_df[diff_name], filtered_df[diff_pred_fold_name], label='实际值', alpha=0.5)\n",
    "    # 绘制横线y=-3.12\n",
    "    plt.axhline(y=threshold_baseline, color='grey', linestyle='--', label=f'y = {threshold_baseline}')\n",
    "\n",
    "    # 绘制竖线x=-3.12\n",
    "    plt.axvline(x=threshold_baseline, color='grey', linestyle='--', label=f'x = {threshold_baseline}')\n",
    "\n",
    "    plt.xlabel(diff_name)\n",
    "    plt.ylabel(diff_pred_fold_name)\n",
    "    plt.title(f'{folds}-fold cross-validation result')\n",
    "    # plt.legend()\n",
    "    # 设置 x 和 y 轴上下限相同\n",
    "    max_limit = max(filtered_df[diff_name].max(), filtered_df[diff_pred_fold_name].max())\n",
    "    min_limit = min(filtered_df[diff_name].min(), filtered_df[diff_pred_fold_name].min())\n",
    "    plt.xlim(min_limit, max_limit)\n",
    "    plt.ylim(min_limit, max_limit)\n",
    "    plt.show()\n",
    "\n",
    "    # 打印平均结果\n",
    "    print(\"\\nMean AUC: {:.2f}\".format(np.mean(roc_auc_list)))\n",
    "    print(\"Mean F1: {:.2f}\".format(np.mean(max_f1_values)))\n",
    "    print(f\"Mean sensitivity: {np.mean(sensitivity_ls):.2f}\")\n",
    "    print(f\"Mean precision: {np.mean(precision_ls):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel('../../data/diff_result_4.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_threshold_dt = {'BME': -1.44, 'SYN': -1.62, 'TS': -1.63, 'inflammation': -3.07}\n",
    "for category, threshold in all_threshold_dt.items():\n",
    "    analysis(category, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
